#rinna/deepseek-r1-distill-qwen2.5-bakeneko-32b-gptq-int8rinna/deepseek-r1-distill-qwen2.5-bakeneko-32b-gptq-int8	-e TRANSFORMERS_OFFLINE=1 \
# --model-impl=transformer--device=auto s

sudo docker run -it \
	--network=host \
	--group-add=video \
	--ipc=host \
	--cap-add=SYS_PTRACE \
	--security-opt seccomp=unconfined \
	--device /dev/kfd \
	--device /dev/dri \
	-v /etc/passwd:/etc/passwd:ro \
	-v /etc/group:/etc/group:ro \
	-e HSA_OVERRIDE_GFX_VERSION=11.0.0 \
	-e VLLM_USE_V1=1 \
	-e VLLM_USE_TRITON_FLASH_ATTN=1 \
	-e FLASH_ATTENTION_TRITON_AMD_ENABLE=TRUE \
	-e FLASH_ATTENTION_TRITON_AMD_AUTOTUNE=TRUE \
	-v $HOME:$HOME:rw \
	-u $(id -u):$(id -g) \
	$(id -G | perl -pe 's/(\d+)/--group-add \1/g') \
	ge-vllm-rocm-0-11-0 \
	bash \
	--norc \
	-c \
	"vllm serve --gpu-memory-utilization=0.98 --max-model-len=32768 --enable-auto-tool-choice --tool-call-parser=hermes --served-model-name gpt-4.1 $@"
