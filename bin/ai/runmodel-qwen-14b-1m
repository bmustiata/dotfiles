#!/usr/bin/env bash

vllm serve \\
    --gpu-memory-utilization=0.98 \\
    --model-impl=transformers \\
    --enable-auto-tool-choice \\
    --tool-call-parser=hermes \\
    --served-model-name=gpt-4.1 \\
    --rope-scaling '{\"rope_type\":\"yarn\",\"factor\":4.0,\"original_max_position_embeddings\":32768}' \\
    --max-model-len 131072 \\
    Qwen/Qwen2.5-14B-Instruct-GPTQ-Int8"
